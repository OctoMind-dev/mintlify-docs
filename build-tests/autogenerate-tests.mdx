---
title: Autogenerate tests
description: "Our AI agent will automatically suggest relevant test cases and spawn existing ones to increase your coverage."
icon: "wand-sparkles"
---

## Test autogeneration at sign-up

When you sign up to Octomind, our AI Agent is going on a discovery journey of your site. It takes a screenshot and tries to come up with a few suggestions for relevant tests to start with automatically.

### Cookie banner and login test

First, it's checking if there is a **cookie banner** and a **required login** that need to be tested. "Required login" is relevant for SaaS apps that unfold most of their functionality to logged in users.
If the AI Agent finds a cookie banner on your page, you will see a _critical_ cookie banner recommendation.
Afterwards, if the AI Agent finds a required login, you will see the login test as a _critical_ recommendation once pressing the "create test case" button, which will then prompt you for your login credentials. It will use them to generate and run a **login test**.
It will automatically be added as dependency for other tests when creating new ones, as will the cookie banner one if it's necessary

We can handle [2-factor authentification (2FA)](/advanced/2fa.mdx) and [captcha](/runtime/custom-headers.mdx) in login flows as well, but you will need to help the agent out.

<Frame caption="AI Agent recommends a cookie and login test, 07/2025">
  <img
    src="/images/build/autogeneration-login-found.png"
    alt="AI agent asks for test credentials to autogenerate and run a login test"
  />
</Frame>

<div class="mt-8" />

<Warning>
  These credentials are only usable for username/password logins not for social
  logins. Login using your Google, Facebook, etc. account will not work.
</Warning>

After these tests arIt's possible that the Agent fails to generate a test ([here are some reasons why](/guides/agent-fails)) or needs help with something - the test is highlighed in **yellow**. This is a [step by step guide on how you'll help the Agent by nudging it in the right direction](/guides/help-agent-succeed).

## Spawning existing test cases

Similar to the initial **AI test generation** during project setup you can use the `generate more from here` feature and `create a new test from here` to expand your test case suite.

Go into the test case view and click on the `plus` icon.

You can follow the progress of these newly created tests in the **AI Agent progress bar**.

<Frame caption="AI agent informs what it does when spawning a test case, 10/2024">
  <img
    src="/images/build/generating-more-agent-running.png"
    alt="AI agent informs what it does when spawning a test case"
  />
</Frame>

At the end of the agent run, the Agent should have autogenerated test steps and validated them for each test case. For those that the validation succeeded, it turned the test **ON** into active mode.

Help the Agent when it couldn't quite nail the autogeneration process - **yellow alert** highlights a failed step generation. See how you [help the Agent to generate a test case successfully](/guides/help-agent-succeed).

<Frame caption="Autogenerated test with yellow alert - a test step failed to generate, 10/2024">
  <img
    src="/images/build/generated-test-yellow-alert.png"
    alt="Autogenerated tests with yellow alert - a test step failed to generate"
  />
</Frame>
