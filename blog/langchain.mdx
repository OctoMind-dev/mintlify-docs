---
title: "On Type Safety In LangChain TS"
description: "A journey through LLM output parsing"
icon: "engine"
---

## What Is Langchain?

_All code examples are using LangChain TS on the main branch on September 22nd, 2023 (roughly version 0.0.153)_.

[LangChain](https://python.langchain.com/docs/get_started/introduction) is a library designed to build interaction chains with Large Language Models (LLMs).
The LLM receives a task prompt, and the developer provides tools the model can utilize to solve the task.
For the purposes of this discourse, that's all the intro needed at this point.
I will introduce some technical concepts from the library as we go along.

There are two languages supported by LangChain: Python and JS/TypeScript.
At Octomind, we are using the TypeScript version to implement parts of our AI-based test discoveries.
This has some pros and some cons.
On the con side, we have to live with the fact that the TypeScript implementation is lagging somewhat behind the Python version; in code and even more so in documentation.
This is a solvable issue, if you are willing to trade the documentation for just going through the source code.
On the pro side, we do not need to write another service in a different language, and we get allegedly guaranteed type safety.
I have not loked into how the Python version handles the issues described in the following paragraphs.

## The Issue With Types In LLMs

In LangChain, you can provide a set of tools that may be called by the model if it deems it necessary.
For our purposes, a tool is simply a class with a `_call` function that does something that the model can not do on itself, like click on on a button on a web page.
The arguments to that function are provided by the model.
When your tool implementation depends on the developer knowng the input format (in contrast to just doing something with text generated by the model), LangChain provides [a class called `StructuredTool`](https://github.com/langchain-ai/langchainjs/blob/main/langchain/src/tools/base.ts#L33).
The `StructuredTool` adds a zod schema to the tool, which is used to parse whatever the model decides to call the tool with, so that we can use this knowledge in our code.

Let's build our "click" example under the assumption that we want the model to give us a query selector to click on:

```TypeScript
import { z } from "zod";
import { StructuredTool } from "langchain/tools";

const clickSchema = z.object({
  selector: z.string().describe("The query seletor to click on."),
});

const ClickSchema = z.infer<typeof clickSchema>;

class ClickTool extends StructuredTool<typeof clickSchema> {
  schema = clickSchema;
  name = "click";
  description =
    "left click on an elemt on a web page represented by a query selector";

  protected _call(arg: ClickSchema): Promise<string> {
    // We need to know that arg.selector is a thing here
    return this.click(arg.selector);
  }

  private click(selector: string): Promise<string> {
    // Add actual implementation of clicking
    return Promise.resolve(`Clicked on ${selector}`);
  }
}
```

Now when you look at this class, it seems reasonably simple without a lot of potential for things to go wrong.
But how does the model actually know what schema to supply?
It has no intrinsic functionality for this, it just generates a string response to a prompt.

When LangChain informs the model about the tools at its disposal, it will generate format instructions for each tool.
These instructions define what JSON is, and how to specific schema for each tool looks like that the model should generate when it wants to use a tool.

For this, LangChain will generate an addition to your own prompt that looks something like this:

```text
You have access to the following tools.
You must format your inputs to these tools to match their "JSON schema" definitions below.

"JSON Schema" is a declarative language that allows you to annotate and validate JSON documents.

For example, the example "JSON Schema" instance {"properties": {"foo": {"description": "a list of test words", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}}
would match an object with one required property, "foo". The "type" property specifies "foo" must be an "array", and the "description" property semantically describes it as "a list of test words". The items within "foo" must be strings.
Thus, the object {"foo": ["bar", "baz"]} is a well-formatted instance of this example "JSON Schema". The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.

Here are the JSON Schema instances for the tools you have access to:

click: left click on an elemt on a web page represented by a query selector, args: {"selecctor":{"type":"string","description":"The query seletor to click on."}}
```

## Don't Trust The LLM!

Now we have a best-effort way to make the model call our tool with inputs in the correct schema.
Best effort unfortunately does not guarentee anything.
It is entirely possible, that the model generates input that does **not** adhere to the schema.

So let's take a look at the implementation of `StructuredTool` to see how it deals with that issue.
`StructuredTool.call` is the function that eventually calls our `_call` method from above.
It starts like this:

```TypeScript
async call(
    arg: (z.output<T> extends string ? string : never) | z.input<T>,
    configArg?: Callbacks | RunnableConfig,
    /** @deprecated */
    tags?: string[]
  ): Promise<string> {
    let parsed;
    try {
      parsed = await this.schema.parseAsync(arg);
    } catch (e) {
      throw new ToolInputParsingException(
        `Received tool input did not match expected schema`,
        JSON.stringify(arg)
      );
    }
    // ... more code
```

The signature of `arg` is interpreted as follows:
If parsing my schema can be just a string, this can be a string, or whatever else the schema defines as input.
In our case, our schema can not be string, so this simplifies to the type `{ selector: string }`, or `ClickSchema`.
But is this actually the case?
According to the implementation, we only check that the input actually adheres to the schema inside of `call`.
The signature reads like we have already made some assumptions about the input.
So one might replace the signature with something like

```TypeScript
call: async (arg: (z.output<T> extends string ? string : never) | Json, /*...*/) => Promise<String>;
```

But looking at it further, even this has issues.
The only thing we know for certain is that the model will give us a string.
This means there are two options:

1. `call` really should have the following signature:
   ```TypeScript
   call: async (arg: string, /*...*/) => Promise<String>;
   ```
2. There is another element to this
   - Something must have already decided that the string returned by the model is valid JSON and have parsed it.
   - In case that `z.output<T> extends string`, something somewhere must have already decided that string is an acceptable input format for the tool, and we do not need to parse JSON.
     (A string by itself is not valid JSON, `JSON.parse("foo")` will result in SyntaxError).

## Introducing The OutputParser Class

Of course, the second option is what is happening.
For theÃ­s use case, LangChain provides a concept called `OutputParser`.
Let's take a look at the default one: `StructuredChatAgent.getDefaultOutputParser(/*...*/) => StructuredChatOutputParserWithRetries`.
The `WithRetries` part means that we potentially ask the model to correct the generated string to match the schema in case parsing fails.
We can ignore that for now, since even the "fixed" version is not guaranteed to be correct.
The part that we really care about is the [`parse` method](https://github.com/langchain-ai/langchainjs/blob/main/langchain/src/agents/structured_chat/outputParser.ts#L112):
We don't need to understand every detail, but we can see that this is where the string that the model produces is parsed to JSON, and errors are thrown if it is not valid JSON (this is where the retries come in).

````TypeScript
 /**
   * Parses the given text and returns an `AgentAction` or `AgentFinish`
   * object. If an `OutputFixingParser` is provided, it is used for parsing;
   * otherwise, the base parser is used.
   * @param text The text to parse.
   * @param callbacks Optional callbacks for asynchronous operations.
   * @returns A Promise that resolves to an `AgentAction` or `AgentFinish` object.
   */
  async parse(text: string): Promise<AgentAction | AgentFinish> {
    try {
      const regex = /```(?:json)?(.*)(```)/gs;
      const actionMatch = regex.exec(text);
      if (actionMatch === null) {
        throw new OutputParserException(
          `Could not parse an action. The agent action must be within a markdown code block, and "action" must be a provided tool or "Final Answer"`
        );
      }
      const response = JSON.parse(actionMatch[1].trim());
      const { action, action_input } = response;

      if (action === "Final Answer") {
        return { returnValues: { output: action_input }, log: text };
      }
      return { tool: action, toolInput: action_input || {}, log: text };
    } catch (e) {
      throw new OutputParserException(
        `Failed to parse. Text: "${text}". Error: ${e}`
      );
    }
  }
````

Alright, so from this we we either get `AgentAction` or `AgentFinish`.
We don't need to concern ourself with `AgentFinish`, since it is just a special case to indicate that the interaction with the model is done.
`AgentAction` is defined as

```TypeScript
export type AgentAction = {
    tool: string;
    toolInput: string;
    log: string;
};
```

By now you might have already seen:
Neither `AgentAction`, nor the `StructuredChatOutputParserWithRetries` is generic, and there is no way to connect the type of `toolInput` with our `ClickSchema`.
Since we don't know which tool the agent has actually selected, we can not (easily) use generics to represent the actual type, so this is expected.

But worse, `toolInput` is typed as `string`, even though we just used `JSON.parse` to get it!
Consider the positive case where the model produced output that matches our schema, let's say the string `"{\"selector\": \"myCoolButton\"}"` (wrapped in all the extra fluff LangChain requires to correctly parse).
Using `JSON.parse`, this will deserialize to an object `{ selector: "myCoolButton" }`, and **not** a `string`.
But because `JSON.parse`'s return type is `any`, the typescript compiler has no chance of realizing this.
unfortunately for us, this also means that we as developers have a hard time to realize this.

## Why Do We Care?

To understand why this is troublesome, we need to look into the execution loop where the `AgentAction`s are used to actually invoke the tool.
This happens [here](https://github.com/langchain-ai/langchainjs/blob/main/langchain/src/agents/executor.ts#L131) in `AgentExecutor._call`.
We don't really need to know all that this class does.
Think of it as the wrapper that handles the interaction of the model with the tool implementations to actually call them.
The `_call` method is quite long, so here is a reduced version that only contains parts relevant for our problem (these methods are simplified parts of `_call` and not in the actual code base of LangChain).

```TypeScript
  async safePlanNextStep(previousSteps: AgentStep[]): Promise<AgentAction> {
    try {
      // This will return either an AgentAction or AgentFinish through outputParser.parse
      output = await this.agent.plan(steps, inputs);
    } catch (e) {
      if (e instanceof OutputParserException) {
        let observation;
        const text = e.message;
        if (this.handleParsingErrors === true) {
          observation = "Invalid or incomplete response";
        } else if (typeof this.handleParsingErrors === "string") {
          observation = this.handleParsingErrors;
        } else if (typeof this.handleParsingErrors === "function") {
          observation = this.handleParsingErrors(e);
        } else {
          throw e;
        }
        output = {
          tool: "_Exception",
          toolInput: observation,
          log: text,
        } as AgentAction;
      } else {
        throw e;
      }
    }
  }
```

The first thing that happens in the loop is to look for the next action to execute.
This is where the parsing using the `OutputParser` comes in, and where its exceptions are handled.
You can see that in the case of an error, the `toolInput` field will always be a string (if `this.handleParsingErrors` is a function, the return type is also `string`).
But we have just seen above, that in the non-error case `toolInput` will be parsed JSON!
This is inconsistent behavior, we never parse the output of `handleParsingErrors` to JSON.
Let's look at how the loop continues.
The next step is to call the selected tool with the given input:

```TypeScript
async safeCallTool(action: AgentAction): Promise<AgentStep> {
  const tool =
    action.tool === "_Exception"
      ? new ExceptionTool()
      : toolsByName[action.tool?.toLowerCase()];
  let observation;
  try {
    observation = tool
      ? await tool.call(action.toolInput)
      : `${action.tool} is not a valid tool, try another one.`;
  } catch (e) {
    if (e instanceof ToolInputParsingException) {
      if (this.handleParsingErrors === true) {
        observation = "Invalid or incomplete tool input. Please try again.";
      } else if (typeof this.handleParsingErrors === "string") {
        observation = this.handleParsingErrors;
      } else if (typeof this.handleParsingErrors === "function") {
        observation = this.handleParsingErrors(e);
      } else {
        throw e;
      }
      observation = await new ExceptionTool().call(
        observation,
        runManager?.getChild()
      );
      return { action, observation: observation ?? "" };
    }
  }

  return { action, observation: observation ?? "" };
}
```

We only pass the previously computed output on to the tool in `tool.call(action.toolInput)`!
And in case this causes another error, we re-use the same function to handle parsing errors that will return a string that is supposed to be the tool output in the error case.

Let's summarize:

- We parse the model's output to JSON and use that parsed result to call a tool
- If the parsing succees, we call the tool with any valid JSON
- If the parsing fails, we call the tool with a string
- The tool parses the input with zod, which will only work in the error case if the schema is just a `const stringSchema = z.string()`
- (We have not covered this, but using `const stringSchema = z.string()` as the tool schema will not type check at all, since the generic argument of `StructuredTool` is `T extends z.ZodObject<any, any, any, any>`, and `typeof stringSchema` does not fulfill that constraint)
- The signature of `tool.call` allows this to type check, since we don't know specifically which tool we have at the moment, so string and any json is potentially valid
- The actual type check for this happens at runtime inside this function
- The developer implementing the tool has no idea about this. Since only `StrucStep.actionturedTool._call` is abstract, you will always get what the schema indicates, but `StructuredTool.call` will fail, even if you have supplied a function `handleParsingErrors`.
- Whatever the tool gets called with is serialized into `AgentAction.toolInput: string`, which is not correctly typed
- The library user has access to the `AgentAction`s with wrongly typed `AgentAction`s, since it is possible to request them as a return value of the overall loop using `returnIntermediateSteps=true`.

Whatever the developer does now is definitely not type safe!

## How Did We Run Into This Problem?

At octomind, we are using the `AgentStep`s to extract the test case steps that we want to generate.
We noticed that the model often times makes the same errors with the tool input format.
Recall our `ClickSchema`, which is just `{ selector: string }`.
In our clicking example it would either generate according to the schema, or `{ element: string }`, or just a string which was the value we want, like `"myCoolButton"`.

So we built and auto-fixer for these common error cases.
The fixer basically just checks whether it can fix the input using either of the options above.
The earliest we can inject this code without overwriting a lot of the planning logic that LangChain provides is in `StructuredTool.call`.
We can not handle it using `handleParsingErrors`, since that receveives only the error as input, and not the causing text.
Once you are overwriting `StructuredTool.call`, you are relying on the signature of that function to be correct, which we just saw is not the case.
At this point, you are stuck having to figure out all of the above to see why you are getting wrongly typed inputs.

In conclusion, navigating the intricacies of type safety in LangChain TypeScript can prove to be quite a puzzle.
The library's approach to parsing input and handling errors often leads to unexpected and inconsistent outcomes within the type system.
However, while these hurdles can be frustrating, they also present opportunities to really take a deep dive into the library.

We have opened an [issue](TODO open issue and add link) over at LangChain JS/TS to discuss solutions to these problems.
Feel free to jump in!
